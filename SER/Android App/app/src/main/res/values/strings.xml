<resources>
    <string-array name="data_type_array">
        <item>all</item>
        <item>face</item>
        <item>asr</item>
        <item>ocr</item>
    </string-array>

    <string-array name="emotion_type_array">
        <item>neutral</item>
        <item>happy</item>
        <item>sad</item>
        <item>angry</item>
        <item>surprise</item>
        <item>fear</item>
        <item>disgust</item>
        <item>my current emotion</item>
    </string-array>

    <string name="app_title">Emotion Enhanced Retrieval Engine</string>
    <string name="app_explanation">
        Enter your search query and choose the emotion.\nYou can specify where it should be detected: in faces, speech (asr), text (ocr) or all of them combined.
    </string>
    <string name="welcome"><![CDATA[Welcome to Retri<3er]]></string>
    <string name="app_name"><![CDATA[Retri<3ver]]></string>
    <string name="settings_explanation">"In the settings you can adjust different things like appearance, suggestions and modes. For the suggestions there are three different options: Nearest Nieghbor Search, Large Language Model and no suggestions. The Nearest Neigbor Search suggest new videos based on the direciton of the preference of the user. The Language Model on the other hand aims to improve the query the user gave and suggest results based on that. "</string>
    <string name="search_explanation"><![CDATA[The Retri<3ver App allows you to search multimedia content. This search is not only enhanced with different type of suggestions but also with emotions! ]]></string>
    <string name="sentiment_detection_explanation">"While the app is running your the emotions you display in your face are analyzed. You can see in the home page of the app what the current detected emotion of your face is. "</string>
    <string name="filter_explanation">"With the help of the filters (the two dropdown menus in the home page) you can adjust the search query to your liking. The first drop down menu is for for what emotion you would like to be displayed. Here you can also select your current emotion. The seconds drop down menu is for the datatype in which the emotion is detected. This can be OCR, where the text recognized is analyzed for emotion, ASR so the emotion in speech or the emotion in the faces detected. "</string>


</resources>