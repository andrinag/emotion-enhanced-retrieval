<resources>
    <string-array name="data_type_array">
        <item>all</item>
        <item>face</item>
        <item>asr</item>
        <item>ocr</item>
    </string-array>

    <string-array name="emotion_type_array">
        <item>neutral</item>
        <item>happy</item>
        <item>sad</item>
        <item>angry</item>
        <item>surprise</item>
        <item>fear</item>
        <item>disgust</item>
        <item>my current emotion</item>
    </string-array>

    <string name="app_title">Emotion Enhanced Retrieval Engine</string>
    <string name="app_explanation">
        Enter your search query and choose the emotion.\nYou can specify where it should be detected: in faces, speech (asr), text (ocr) or all of them combined.
    </string>
    <string name="welcome"><![CDATA[Welcome to Retri<3er]]></string>
    <string name="app_name"><![CDATA[Retri<3ver]]></string>
    <string name="settings_explanation">
    In the settings, you can customize various aspects of the app, including appearance, suggestion
        behavior, and search modes. For suggestions, you can choose between three options: Nearest
        Neighbor Search, Large Language Model, or no suggestions at all. Nearest Neighbor Search
        recommends new videos based on your viewing preferences, while the Language Model improves
        your original query to suggest more relevant results.
</string>

    <string name="search_explanation">
    <![CDATA[
    The Retri<3ver App lets you search multimedia content in an emotion-enhanced way. Include
    emotions into your search and get tailored real-time suggestions based on your emotions.
    ]]>
</string>

    <string name="sentiment_detection_explanation">
    While the app is running, it analyzes the emotions expressed on your face. You can view your
        currently detected emotion directly on the home screen.
</string>

    <string name="filter_explanation">
    Use the filters (the two dropdown menus on the home screen) to fine-tune your search. The first
        dropdown lets you choose the emotion you want to see reflected in the resultsâ€”or you can
        select your own current emotion. The second dropdown selects the data source from which the
        emotion should be detected: OCR (text within images), ASR (spoken language), or facial
        expressions.
</string>
</resources>